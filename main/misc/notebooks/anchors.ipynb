{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cbf8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e91123f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = {\n",
    "    \"image_size\": 224,\n",
    "    \"feature_size\": 56,\n",
    "    \"r_far\": np.sqrt(0.5*0.5 + 0.5*0.5),\n",
    "    \"r_near\": np.sqrt(0.5*0.5 + 0.5*0.5)\n",
    "}\n",
    "\n",
    "# feature map of 56x56 would give 3136 sources which\n",
    "# would be enough. Otherwise maybe 28x28 depends on \n",
    "# images input size as what really matters is density of gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dafe5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchors(config):\n",
    "    \"\"\"\n",
    "    Generates a lattice of anchors for a given image input\n",
    "    size and feature map size. Note the coordinates are \n",
    "    (x,y) indexed!\n",
    "    \n",
    "    Adapted from Duncan Tilley's work on PPN \n",
    "    https://github.com/tilleyd/point-proposal-net/\n",
    "    \n",
    "    config\n",
    "        The configuration dictionary.\n",
    "\n",
    "    Returns the coorinates of the origin anchors (x,y).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Reads sizes\n",
    "    img_size = config['image_size']\n",
    "    feature_size = config['feature_size']\n",
    "    \n",
    "    # Calculates step length for gievn sizes\n",
    "    step = img_size / feature_size\n",
    "    halfstep = step * 0.5\n",
    "    \n",
    "    # Calculates the lattice of points\n",
    "    x = np.arange(halfstep, img_size, step, dtype=np.float32)\n",
    "    y = np.arange(halfstep, img_size, step, dtype=np.float32)\n",
    "    \n",
    "    return np.transpose([np.tile(x, len(y)), np.repeat(y, len(x))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cec069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.   2.]\n",
      " [  6.   2.]\n",
      " [ 10.   2.]\n",
      " ...\n",
      " [214. 222.]\n",
      " [218. 222.]\n",
      " [222. 222.]]\n"
     ]
    }
   ],
   "source": [
    "# testing get_anchors\n",
    "print(get_anchors(test_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd72f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor_labels(anchors, truth_coords, config):\n",
    "    \"\"\"\n",
    "    Creates anchor labels to be used in training.\n",
    "    \n",
    "    Adapted from Duncan Tilley's work on PPN \n",
    "    https://github.com/tilleyd/point-proposal-net/\n",
    "    \n",
    "    anchors\n",
    "        The list of anchor coordinates generated from \n",
    "        get_anchors()\n",
    "    \n",
    "    truth_coords\n",
    "        The list of ground truth point cooridnates.\n",
    "        !!!check (x,y) or (y,x) convention\n",
    "    \n",
    "    config\n",
    "        The configuration dictionary.\n",
    "    \n",
    "    Returns y_conf, y_reg\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    r_near = config['r_near']\n",
    "    r_far = config['r_far']\n",
    "    img_size = config['image_size']\n",
    "    feature_size = config['feature_size']\n",
    "    \n",
    "    step = img_size / feature_size\n",
    "    halfstep = step * 0.5\n",
    "\n",
    "    # Initialising output\n",
    "    y_conf = np.full(anchors.shape[0], -1, dtype=np.int8)\n",
    "    y_reg = np.zeros(anchors.shape)\n",
    "    \n",
    "    # For each true point, find the nearest anchor\n",
    "    for (x, y) in truth_coords:\n",
    "        \n",
    "        # Normalising truth points to step size\n",
    "        x_norm = (x - halfstep) / step\n",
    "        y_norm = (y - halfstep) / step\n",
    "        \n",
    "        # Finding index of closest anchor by rounding\n",
    "        r = int(np.round(y_norm))\n",
    "        c = int(np.round(x_norm))   \n",
    "        anchor_index = r * feature_size + c\n",
    "        \n",
    "        # Setting values for anchor index\n",
    "        y_conf[anchor_index] = 1\n",
    "        y_reg[anchor_index][0] = (x - anchors[anchor_index][0]) / step\n",
    "        y_reg[anchor_index][1] = (y - anchors[anchor_index][1]) / step\n",
    "    \n",
    "    # For each anchor calculate the distance to each point\n",
    "    for i in range(len(anchors)):\n",
    "        x, y = anchors[i]\n",
    "        x /= step\n",
    "        y /= step\n",
    "        distances = []\n",
    "        for (px, py) in truth_coords:\n",
    "            px /= step\n",
    "            py /= step\n",
    "            distances.append(np.sqrt((x-px)**2 + (y-py)**2))\n",
    "        if len(distances) > 0:\n",
    "            near = np.argmin(distances)\n",
    "            dist = distances[near]\n",
    "            if dist <= r_near:\n",
    "                y_conf[i] = 1\n",
    "                px, py = truth_coords[near]\n",
    "                px /= step\n",
    "                py /= step\n",
    "                y_reg[i][0] = (px - x)\n",
    "                y_reg[i][1] = (py - y)\n",
    "            elif dist > r_far:\n",
    "                y_conf[i] = 0\n",
    "                \n",
    "    # reshape for use in PPN training\n",
    "    y_conf = np.reshape(y_conf, (feature_size, feature_size))\n",
    "    y_reg = np.reshape(y_reg, (feature_size, feature_size) + (2,))\n",
    "    return y_conf, y_reg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb115047",
   "metadata": {},
   "source": [
    "try to avoid sqrt calculations as slow, could compare non-rooted values then just root the required value.\n",
    "https://stackoverflow.com/questions/62400420/given-two-lists-of-2d-points-how-to-find-the-closest-point-in-the-2nd-list-for\n",
    "\n",
    "speed here isn't really an issue so wouldn't worry about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f565db79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "#gt = np.array([[10,10],[100,50],[200,200]])\n",
    "gt = np.random.randint(0,224,size=(1000,2))\n",
    "anchs = get_anchors(test_config)\n",
    "x = get_anchor_labels(anchs, gt, test_config)\n",
    "print(gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f2f850c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 447)\n"
     ]
    }
   ],
   "source": [
    "gt1 = np.random.randint(0,224,size=(2,447)) #define as (y,x) \n",
    "# Need to transform to shape (447,2) with first collumn x second y\n",
    "\n",
    "\n",
    "\n",
    "print(gt1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "922bed69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.    0.  ]\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.    0.  ]\n",
      "  ...\n",
      "  [-0.25 -0.5 ]\n",
      "  [ 0.    0.  ]\n",
      "  [-0.25  0.  ]]\n",
      "\n",
      " [[ 0.    0.  ]\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.5  -0.25]\n",
      "  ...\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.    0.  ]]\n",
      "\n",
      " [[ 0.    0.  ]\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.    0.  ]\n",
      "  ...\n",
      "  [ 0.25  0.  ]\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.    0.  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.    0.  ]\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.    0.  ]\n",
      "  ...\n",
      "  [-0.25  0.5 ]\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.    0.  ]]\n",
      "\n",
      " [[ 0.25 -0.25]\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.25  0.25]\n",
      "  ...\n",
      "  [ 0.    0.25]\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.    0.  ]]\n",
      "\n",
      " [[-0.5  -0.25]\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.    0.  ]\n",
      "  ...\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.    0.  ]\n",
      "  [ 0.    0.  ]]]\n"
     ]
    }
   ],
   "source": [
    "print(x[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
